{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining an Example Model\n",
    "\n",
    "In the next section, we define a simple 2-layer sparse DGP model for a regression task. Weâ€™ll be using this model to demonstrate the usage of the library."
   ],
   "id": "1b1e2221e44c7cac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:31:39.975952Z",
     "start_time": "2024-05-20T17:31:39.972292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import sparse_dgp as gp\n",
    "from sparse_dgp.layers.linear import LinearReparameterization\n",
    "from sparse_dgp.layers.activations import TMGP"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Defining a 2-layer DTMGP Model\n",
    "\n",
    "First, we define a 2-layer DTMGP model with a single output dimension. The model consists of two layers, each with level-3 sparse grid design."
   ],
   "id": "7767bd7948758eb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:31:40.043689Z",
     "start_time": "2024-05-20T17:31:40.008728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a 2-layer DTMGP model for regression\n",
    "class SparseDGP_grid(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, design_class, kernel):\n",
    "        super(SparseDGP_grid, self).__init__()\n",
    "        \n",
    "        # 1st layer of DGP: input:[n, input_dim] size tensor, output:[n, w1] size tensor\n",
    "        self.tmk1 = TMGP(in_features=input_dim, n_level=3, design_class=design_class, kernel=kernel)\n",
    "        self.fc1 = LinearReparameterization(\n",
    "            in_features=self.tmk1.out_features, \n",
    "            out_features=8, \n",
    "            prior_mean=0.0, \n",
    "            prior_variance=1.0, \n",
    "            posterior_mu_init=0.0, \n",
    "            posterior_rho_init=-3.0, \n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        # 2nd layer of DGP: input:[n, w1] size tensor, output:[n, output_dim] size tensor\n",
    "        self.tmk2 = TMGP(in_features=8, n_level=3, design_class=design_class, kernel=kernel)\n",
    "        self.fc2 = LinearReparameterization(\n",
    "            in_features=self.tmk2.out_features, \n",
    "            out_features=output_dim, \n",
    "            prior_mean=0.0, \n",
    "            prior_variance=1.0, \n",
    "            posterior_mu_init=0.0, \n",
    "            posterior_rho_init=-3.0, \n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        kl_sum = 0\n",
    "\n",
    "        x = self.tmk1(x)\n",
    "        x, kl = self.fc1(x)\n",
    "        kl_sum += kl\n",
    "\n",
    "        x = self.tmk2(x)\n",
    "        x, kl = self.fc2(x)\n",
    "        kl_sum += kl\n",
    "\n",
    "        return torch.squeeze(x), kl_sum"
   ],
   "id": "5f19e34aab5634b8",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing the Data\n",
    "\n",
    "We set up the training data for this example. We'll be using 1000 regularly spaced points in the range [0, 1] as input data. The output data is generated by a function that takes the input data and adds Gaussian noise to get the training labels."
   ],
   "id": "4681af98afe7c813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:31:40.053681Z",
     "start_time": "2024-05-20T17:31:40.045416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_x = torch.linspace(0, 1, 300)\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.1\n",
    "\n",
    "class SineDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "dataset = SineDataset(train_x, train_y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ],
   "id": "ae83117d86eb8504",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing the Model and the Optimizer",
   "id": "73f0a7e87bd85a2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:31:41.834350Z",
     "start_time": "2024-05-20T17:31:40.054908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sparse_dgp.utils.sparse_activation.design_class import HyperbolicCrossDesign\n",
    "from sparse_dgp.kernels.laplace_kernel import LaplaceProductKernel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using: \", device)\n",
    "\n",
    "model = SparseDGP_grid(input_dim=1, \n",
    "                       output_dim=1, \n",
    "                       design_class=HyperbolicCrossDesign, \n",
    "                       kernel=LaplaceProductKernel(1.),\n",
    "                       ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "id": "60d11360be6a6280",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  cuda\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the Model",
   "id": "440609ecdd176828"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:31:50.899375Z",
     "start_time": "2024-05-20T17:31:41.835516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_ = []\n",
    "        kl_ = []\n",
    "        for mc_run in range(1):\n",
    "            output, kl = model(data)\n",
    "            output_.append(output)\n",
    "            kl_.append(kl)\n",
    "        output = torch.mean(torch.stack(output_), dim=0)\n",
    "        kl = torch.mean(torch.stack(kl_), dim=0)\n",
    "        nll_loss = F.mse_loss(output, target)\n",
    "        # ELBO loss\n",
    "        loss = nll_loss + (kl / 8)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ],
   "id": "8f8ef20ddad946c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.2616976499557495\n",
      "Epoch: 1, Loss: 1.100917935371399\n",
      "Epoch: 2, Loss: 1.0582685470581055\n",
      "Epoch: 3, Loss: 0.950246274471283\n",
      "Epoch: 4, Loss: 0.8577843308448792\n",
      "Epoch: 5, Loss: 0.8147437572479248\n",
      "Epoch: 6, Loss: 0.6811959147453308\n",
      "Epoch: 7, Loss: 1.0003430843353271\n",
      "Epoch: 8, Loss: 0.723312497138977\n",
      "Epoch: 9, Loss: 0.7210695147514343\n",
      "Epoch: 10, Loss: 0.923382043838501\n",
      "Epoch: 11, Loss: 0.6909069418907166\n",
      "Epoch: 12, Loss: 0.6228176951408386\n",
      "Epoch: 13, Loss: 0.7014390230178833\n",
      "Epoch: 14, Loss: 0.6350182294845581\n",
      "Epoch: 15, Loss: 0.5633167028427124\n",
      "Epoch: 16, Loss: 0.6716229915618896\n",
      "Epoch: 17, Loss: 0.6238070130348206\n",
      "Epoch: 18, Loss: 0.5351642966270447\n",
      "Epoch: 19, Loss: 0.5005326271057129\n",
      "Epoch: 20, Loss: 0.7072726488113403\n",
      "Epoch: 21, Loss: 0.6460894346237183\n",
      "Epoch: 22, Loss: 0.5426713228225708\n",
      "Epoch: 23, Loss: 0.49523478746414185\n",
      "Epoch: 24, Loss: 0.42837417125701904\n",
      "Epoch: 25, Loss: 1.3395843505859375\n",
      "Epoch: 26, Loss: 1.6528364419937134\n",
      "Epoch: 27, Loss: 0.40847164392471313\n",
      "Epoch: 28, Loss: 0.8572891354560852\n",
      "Epoch: 29, Loss: 1.3607244491577148\n",
      "Epoch: 30, Loss: 0.40499183535575867\n",
      "Epoch: 31, Loss: 0.9270737767219543\n",
      "Epoch: 32, Loss: 0.5561547875404358\n",
      "Epoch: 33, Loss: 0.4345351755619049\n",
      "Epoch: 34, Loss: 0.49680113792419434\n",
      "Epoch: 35, Loss: 0.576563835144043\n",
      "Epoch: 36, Loss: 0.5855127573013306\n",
      "Epoch: 37, Loss: 0.4308025538921356\n",
      "Epoch: 38, Loss: 0.8657546043395996\n",
      "Epoch: 39, Loss: 0.385064959526062\n",
      "Epoch: 40, Loss: 0.5231159329414368\n",
      "Epoch: 41, Loss: 0.46742749214172363\n",
      "Epoch: 42, Loss: 0.3509191870689392\n",
      "Epoch: 43, Loss: 0.4578104019165039\n",
      "Epoch: 44, Loss: 0.34831351041793823\n",
      "Epoch: 45, Loss: 0.9175736308097839\n",
      "Epoch: 46, Loss: 0.8482086658477783\n",
      "Epoch: 47, Loss: 0.4944136142730713\n",
      "Epoch: 48, Loss: 0.752888560295105\n",
      "Epoch: 49, Loss: 0.8036465048789978\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T17:31:50.902462Z",
     "start_time": "2024-05-20T17:31:50.900386Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "984e08a8d9562182",
   "outputs": [],
   "execution_count": 125
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
